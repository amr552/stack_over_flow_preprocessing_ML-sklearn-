# -*- coding: utf-8 -*-
"""basedonLec_preprocessing_sklearn.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bYVstygoIBxq88AtvV5cLr0V87iM04Y0
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

df=pd.read_csv('/content/drive/MyDrive/datasets/DS Mostafa Othman dataset/feature engineer dataset/stackoverflow-dirty - stackoverflow-dirty.csv')
df.sample(3)

"""## Handling Missing Data"""

df.isnull().sum()

df.info()

sns.heatmap(df.isnull())

df.drop(columns='RawSalary',inplace=True)

df[['ConvertedSalary','Age','Years Experience']].describe()

# df['ConvertedSalary'].plot(kind='box')
sns.violinplot(df['ConvertedSalary'])

"""####the target record is ConvertedSalary but there are missing vlues and also outliers

I have two option

    1. treating the outlier values so i could fill the missing values with mean of the values
    2. filling the missing values with the median values and this option make sence to me

#### filling the missing values by using sklearn

#### Treating the outliers values
"""

Q1=df['ConvertedSalary'].quantile(0.25)
Q3=df['ConvertedSalary'].quantile(0.75)
IQR= Q3-Q1
lower_bound=Q1-1.5*IQR
upper_bound=Q3+1.5*IQR
lower_bound, upper_bound

df['ConvertedSalary']=df['ConvertedSalary'].clip(lower_bound,upper_bound)
sns.boxplot(df['ConvertedSalary'])
# sns.violinplot(df['ConvertedSalary'])

sns.violinplot(df['ConvertedSalary'])

df.boxplot(column=['Age','Years Experience'])

Q1=df['Age'].quantile(0.25)
Q3=df['Age'].quantile(0.75)
IQR= Q3-Q1
lower_bound=Q1-1.5*IQR
upper_bound=Q3+1.5*IQR
lower_bound, upper_bound

df['Age']=df['Age'].clip(lower_bound,upper_bound)

Q1=df['Years Experience'].quantile(0.25)
Q3=df['Years Experience'].quantile(0.75)
IQR= Q3-Q1
lower_bound=Q1-1.5*IQR
upper_bound=Q3+1.5*IQR
lower_bound, upper_bound

df['Years Experience']=df['Years Experience'].clip(lower_bound,upper_bound)

for column in ['Age', 'Years Experience']:
    sns.violinplot(df[column])
    plt.show()

"""#### Filling missing values by using sklearn"""

from sklearn.impute import MissingIndicator, SimpleImputer
miss=MissingIndicator()
miss.fit_transform(df[['ConvertedSalary']]).sum()

fillmean=SimpleImputer(strategy='mean')
df['ConvertedSalary']=fillmean.fit_transform(df[['ConvertedSalary']])
miss.fit_transform(df[['ConvertedSalary']]).sum()

df[['ConvertedSalary','Age','Years Experience']].plot(subplots=True,figsize=(10,8))

df.info()

"""#### Scalling the range of the values"""

df.describe()

from sklearn.preprocessing import MinMaxScaler, StandardScaler
## standardscaler for more than 3 categories
stand=StandardScaler()
minmax=MinMaxScaler()
df['ConvertedSalary']=minmax.fit_transform(df[['ConvertedSalary']])
df['Years Experience']=minmax.fit_transform(df[['Years Experience']])
df['Age']=minmax.fit_transform(df[['Age']])

df['ConvertedSalary']

df[['Age','FormalEducation','Country','VersionControl','Years Experience','Gender','ConvertedSalary']].sample(3)

df['Country'].value_counts()

from sklearn.preprocessing import LabelEncoder
'''
from sklearn.preprocessing import LabelEncoder, OneHotEncoder
# labelencoder for more than 3 categories
label=LabelEncoder()
df['Country_encoded']=label.fit_transform(df['Country'])
df[['Country','Country_encoded']].drop_duplicates()
'''
label_encoders = {}
country_le = LabelEncoder()

df['Country_encoded'] = country_le.fit_transform(df['Country'])
label_encoders['Country'] = country_le

print("LabelEncoder for 'Country' has been stored in 'label_encoders['Country']'.")
print("You can access the original labels via its '.classes_' attribute.")
print("For example, the mapping from encoded integer to original country is:")
print({idx: label for idx, label in enumerate(country_le.classes_)})

# --- How to use the stored encoder to retrieve original values ---
# To retrieve an original value from an encoded value, for instance, for an encoded_value = 4:
# original_country = label_encoders['Country'].inverse_transform([4])[0]
# print(f"\nExample: Original country for encoded value 4 is: {original_country}")

# You should apply a similar pattern for 'FormalEducation' and 'VersionControl'
# in their respective encoding cells to also store their LabelEncoder objects.

df['FormalEducation'].value_counts()

major_degrees = ['Bachelor\'s degree (BA. BS. B.Eng.. etc.)', 'Master\'s degree (MA. MS. M.Eng.. MBA. etc.)']
other_education_mask = ~df['FormalEducation'].isin(major_degrees)
other_education_values = df.loc[other_education_mask, 'FormalEducation'].unique().tolist()

# This cell was intended to get the 'other' education levels, so it should be used to define 'unique_other_education'
unique_other_education = other_education_values

df['FormalEducation'] = df['FormalEducation'].replace(unique_other_education, 'levels_low_Bsc')

df['FormalEducation'].value_counts()

'''
df['FormalEducation_encoded']=label.fit_transform(df['FormalEducation'])
df[['FormalEducation','FormalEducation_encoded']].drop_duplicates()
'''
label_encoders = {}
education_le = LabelEncoder()

df['FormalEducation'] = education_le.fit_transform(df['FormalEducation'])
label_encoders['FormalEducation'] = education_le

print("LabelEncoder for 'education' has been stored in 'label_encoders['education']'.")
print("You can access the original labels via its '.classes_' attribute.")
print("For example, the mapping from encoded integer to original country is:")
print({idx: label for idx, label in enumerate(education_le.classes_)})

other_versions = df[df['VersionControl'] != 'Git']['VersionControl']
unique_other_versions = other_versions.unique().tolist()

df['VersionControl'] = df['VersionControl'].replace(unique_other_versions, 'other_version_of_git')
df['VersionControl'].value_counts()
#

version_control_le = LabelEncoder()
df['VersionControl_encoded'] = version_control_le.fit_transform(df['VersionControl'])
label_encoders['VersionControl'] = version_control_le

print("LabelEncoder for 'VersionControl' has been stored in 'label_encoders['VersionControl']'.")
print("You can access the original labels via its '.classes_' attribute.")
print("For example, the mapping from encoded integer to original version control is:")
print({idx: label for idx, label in enumerate(version_control_le.classes_)})

# Display unique original and encoded values
df[['VersionControl','VersionControl_encoded']].drop_duplicates()



df.info()

X=df[['FormalEducation','Country_encoded','VersionControl_encoded','Age','Years Experience']]
y=df['ConvertedSalary']

X

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,train_size=0.8,random_state=101)

"""### creating the model by using different algorithms

#### linear regression algorithm
"""

from sklearn.linear_model import LinearRegression
lr=LinearRegression()
lr.fit(X_train,y_train)

lr.score(X_train, y_train)

"""#### support verctor regression (SVR)

"""

from sklearn.svm import SVR
svr=SVR(C=1000)
svr.fit(X_train,y_train)

svr.score(X_train, y_train)

"""#### Knearest neighbour Regression"""

from sklearn.neighbors import KNeighborsRegressor
knn=KNeighborsRegressor(n_neighbors=1)
knn.fit(X_train, y_train)

knn.score(X_train, y_train)

"""#### Random Forest Regression"""

from sklearn.ensemble import RandomForestRegressor
rf=RandomForestRegressor()
rf.fit(X_train, y_train)

rf.score(X_train, y_train)

"""#### XGBoost"""

from xgboost import XGBRegressor
xgb=XGBRegressor()
xgb.fit(X_train, y_train)

# The XGBoost model expects feature names without the '_encoded' suffix
# based on the error message, even though X_train has them.
# We will temporarily rename X_train's columns to match the model's expectation for scoring.
X_train_for_scoring = X_train.copy()
X_train_for_scoring.rename(columns={
    'FormalEducation_encoded': 'FormalEducation_encoded',
    'Country_encoded': 'Country_encoded',
    'VersionControl_encoded': 'VersionControl_encoded',
    'Age': 'Age',
    'Years Experience': 'Years Experience'
}, inplace=True)

xgb.score(X_train_for_scoring, y_train)

"""## saving my model"""

import joblib
joblib.dump(knn, '/content/drive/MyDrive/datasets/DS Mostafa Othman dataset/created_models/stackoverflow_salary_predict.pkl')